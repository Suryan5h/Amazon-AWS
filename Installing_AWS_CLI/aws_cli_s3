# S3 Commands
# Creating a bucket - mb command
aws s3 mb s3://unique_bucket_name

# Listing the buckets in S3 - ls command
aws s3 ls

# Copying a file from local machine to S3 bucket - cp command
aws s3 cp ./test.json s3://unique_bucket_name/file_name.json

# Listing the objects in the bucket - ls command
aws s3 ls s3://unique_bucket_name

# Removing a file from the bucket - rm command
aws s3 rm s3://unique_bucket_name/file_name.json

# Removing all the files from the bucket - rm command
aws s3 rm --recursive s3://unique_bucket_name

# Removing the bucket - rb command
aws s3 rb s3://unique_bucket_name

cp: To copy objects. It can be used to upload and download files from S3 to the local machine
ls: To list the buckets/objects in S3
mb: To create a new S3 bucket
mv: To move the objects present on the local disk or in S3
presign: To provide a pre-signed URL for an Amazon S3 object
rb: To remove an empty bucket
rm: To remove an object
sync: To sync the directories present in S3
website: To set the website configuration for a bucket


**************
Question: Suppose you work in an e-commerce company that keeps records of multiple products (more than a thousand) in the S3 bucket ‘records’. The files have the following structure for filename: ‘category-productid.csv’. 

You have to analyse the records associated with the ‘Electronics’ category only. You are expected to download specific category reports and then perform analysis over your local machine. 

Provide the command that helps you perform this task.


Hint: Explore the help section under the S3 service.


Answer: 
You can use the Exclude and Include filters to obtain the required objects. To download all the files associated with a particular category, you must use the --exclude and --include attribute together with the cp command under S3. Also, to check each file in the bucket, you have to use the recursive function:

aws s3 cp s3://records “local_path” --recursive --exclude “*” --include “electronics*”

Through this task, you must have realised the power of the AWS CLI and also learnt how it is better than the Management Console in performing challenging tasks.

